{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the CSV Files from: \n",
    "* 2018 yellow cab taxi rides (112M lines; may sample down to 1M for convenience): https://data.cityofnewyork.us/Traasportation/2018-Yellow-Taxi-Trip-Data/t29m-gskq\n",
    "* taxi zone names and polygons: https://data.cityofnewyork.us/Transportation/NYC-Taxi-Zones/d3c5-ddgc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store them in this directory (\"datasets\") as `taxis.csv` and `taxi_zones.csv`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform/Filter the data for use with the sampling pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precompute polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import MultiPolygon, Point\n",
    "\n",
    "rides_df = pd.read_csv(\"./taxis.csv\", delimiter=\";\", parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "zones_df = pd.read_csv(\"./taxi_zones.csv\")\n",
    "\n",
    "\n",
    "zones_df = zones_df[[\"LocationID\", \"the_geom\"]].set_index(\"LocationID\")\n",
    "rides_df = rides_df.join(zones_df, on=\"PULocationID\")\n",
    "rides_df = rides_df.join(zones_df, on=\"DOLocationID\", rsuffix=\"DO\")\n",
    "\n",
    "\n",
    "# only keep rows with a dropoff and a pickup point (i.e., no NaN entries)\n",
    "rides_df = rides_df[rides_df[\"the_geom\"].notnull() & rides_df[\"the_geomDO\"].notnull()]\n",
    "\n",
    "# only keep rows with a pickup and dropoff date in 2018 as simple data cleaning (but there are some \n",
    "# rides around New Year that get discarded, though)\n",
    "rides_df = rides_df[rides_df[\"tpep_pickup_datetime\"].dt.year == 2018]\n",
    "rides_df = rides_df[rides_df[\"tpep_dropoff_datetime\"].dt.year == 2018]\n",
    "\n",
    "# make temporal dimensions numeric (some parts of the pipeline break when data is string or object)\n",
    "rides_df[\"tpep_pickup_datetime\"] = rides_df[\"tpep_pickup_datetime\"].astype(np.int64)\n",
    "rides_df[\"tpep_dropoff_datetime\"] = rides_df[\"tpep_dropoff_datetime\"].astype(np.int64)\n",
    "\n",
    "def generate_representative(poly: MultiPolygon):\n",
    "  '''Computes a random location inside the polygon until that location actually lies inside the \n",
    "     polygon. This random location is used as a representative point for the polygon in the \n",
    "     dataset.'''\n",
    "  min_x, min_y, max_x, max_y = poly.bounds\n",
    "  pos = [-1, -1]\n",
    "  is_inside = False\n",
    "  while not is_inside:\n",
    "    pos[0] = random.uniform(min_x, max_x)\n",
    "    pos[1] = random.uniform(min_y, max_y)\n",
    "    is_inside = poly.contains(Point(pos))\n",
    "  return np.array(pos).reshape(2, 1)\n",
    "\n",
    "# generate a representative geo point for each taxi ride's pick-up and drop-off location, so that \n",
    "# we can linearize by geospace\n",
    "PUrepresentatives = rides_df.apply(\n",
    "  lambda row: generate_representative(loads(row[\"the_geom\"])), \n",
    "  axis=1\n",
    ")\n",
    "\n",
    "# np.stack turns array of objects into array of arrays\n",
    "PUrepresentatives = np.stack(PUrepresentatives)\n",
    "\n",
    "DOrepresentatives = rides_df.apply(\n",
    "  lambda row: generate_representative(loads(row[\"the_geomDO\"])), \n",
    "  axis=1\n",
    ")\n",
    "DOrepresentatives = np.stack(DOrepresentatives)\n",
    "\n",
    "# store lat and lng as separate attributes\n",
    "rides_df[\"PUrepresentativeX\"] = PUrepresentatives[:, 0]\n",
    "rides_df[\"PUrepresentativeY\"] = PUrepresentatives[:, 1]\n",
    "rides_df[\"DOrepresentativeX\"] = DOrepresentatives[:, 0]\n",
    "rides_df[\"DOrepresentativeY\"] = DOrepresentatives[:, 1]\n",
    "\n",
    "# drop unneeded geometry and non-numerical cols\n",
    "rides_df.drop(columns=[\"the_geom\", \"the_geomDO\", \"store_and_fwd_flag\"], inplace=True)\n",
    "\n",
    "# write the update data back to the file\n",
    "rides_df.to_csv(\"./taxisData.csv\", sep=\";\", index=False, header=False)\n",
    "# takes about 15:30 minutes for 1M "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precompute spatial autocorrelation (run the previous cell first!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "# reproduces the autocorrelation computation outlined here: \n",
    "# https://geographicdata.science/book/notebooks/06_spatial_autocorrelation.html\n",
    "\n",
    "# find the knn for each point\n",
    "columns = [\"tripID\", \"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"RatecodeID\", \"PULocationID\", \"DOLocationID\", \"payment_type\", \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\", \"PURepresentativeX\", \"PURepresentativeY\", \"DORepresentativeX\", \"DORepresentativeY\"]\n",
    "\n",
    "rides_df = pd.read_csv(\"./taxisData.csv\", delimiter=\";\", names=columns)\n",
    "\n",
    "\n",
    "X = rides_df.to_numpy()\n",
    "\n",
    "# constants for indeces of important columns in the np array \n",
    "LAT = 17\n",
    "LON = 18\n",
    "TRIP_DISTANCE = 5\n",
    "TRIP_ID = 0\n",
    "\n",
    "tree = KDTree(X[:, [LAT, LON]])\n",
    "dist, knn = tree.query(X[:, [LAT, LON]], k=9)  # using k=8 (+1, as first match is item itself)\n",
    "\n",
    "# first match to query is the item itself, so remove that one\n",
    "dist = dist[:, 1:]\n",
    "knn = knn[:, 1:]\n",
    "\n",
    "# compute the weights for the knn per point (the closer, the greater the weight)\n",
    "w = 1 / dist \n",
    "w = w / w.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "# compute the weighted knn value per point (i.e., the spatial lag)\n",
    "knn_value = X[knn][:, :, TRIP_DISTANCE]  # get the value column per neighbor\n",
    "spatial_lag = knn_value * w  # multiply the value vector with weights\n",
    "spatial_lag = spatial_lag.sum(axis=1)\n",
    "\n",
    "# compute the normalized actual value\n",
    "mean_value = np.mean(X[:, TRIP_DISTANCE], axis=0)\n",
    "normalized_value = X[:, TRIP_DISTANCE] - mean_value\n",
    "\n",
    "# compute the normalized lag value\n",
    "mean_spatial_lag = np.mean(spatial_lag, axis=0)\n",
    "normalized_spatial_lag = spatial_lag - mean_spatial_lag\n",
    "\n",
    "# compute the H/L labels, indicating the quadrants in the Moran's plot\n",
    "value_is_H = normalized_value > 0\n",
    "spatial_lag_is_H = normalized_spatial_lag > 0\n",
    "# value_is_H.astype(int) + spatial_lag_is_H.astype(int)\n",
    "\n",
    "spatial_auto_df = pd.DataFrame(\n",
    "  np.array([\n",
    "    X[:, TRIP_ID], \n",
    "    normalized_value,\n",
    "    normalized_spatial_lag,\n",
    "    value_is_H,\n",
    "    spatial_lag_is_H,\n",
    "  ]).T,\n",
    "  columns=[\n",
    "    \"tripID\",\n",
    "    \"normalized_value\",\n",
    "    \"normalized_spatial_lag\",\n",
    "    \"value_is_H\",\n",
    "    \"spatial_lag_is_H\"\n",
    "  ],\n",
    ").set_index(\"tripID\")\n",
    "rides_df.astype({\"tripID\": int}).set_index(\"tripID\").join(spatial_auto_df).to_csv(\"taxisData.csv\", sep=\";\", index=True, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moran Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://geographicdata.science/book/notebooks/06_spatial_autocorrelation.html\n",
    "fig, ax = plt.subplots(1, figsize=(12, 6))\n",
    "sns.regplot(\n",
    "  x=normalized_value,\n",
    "  y=normalized_spatial_lag,\n",
    "  # ci=None,\n",
    "  color=\"r\",\n",
    "  scatter_kws={\"s\": 0.1, \"alpha\": 0.3}\n",
    ")\n",
    "ax.axvline(0, c=\"k\", alpha=0.5)\n",
    "ax.axhline(0, c=\"k\", alpha=0.5)\n",
    "ax.set_title('Moran Plot - trip_distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = [\"tripID\", \"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"RatecodeID\", \"PULocationID\", \"DOLocationID\", \"payment_type\", \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\", \"PURepresentativeX\", \"PURepresentativeY\", \"DORepresentativeX\", \"DORepresentativeY\", \"normalized_value\", \"normalized_spatial_lag\", \"value_is_H\", \"spatial_lag_is_H\"]\n",
    "\n",
    "rides_df = pd.read_csv(\"./taxisData.csv\", sep=\";\", names=columns)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "rides_df.describe().loc[[\"min\", \"max\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precompute linearizations\n",
    "WE precompute linearizations and store them in CSV files in `../linearization_files/` to reduce loading times.\n",
    "\n",
    "***Note** that you must run this cell to recreate the figures in `figures.ipynb`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(f\"{os.getcwd()}/../../../\")  # HACK to make relative imports work in notebooks\n",
    "\n",
    "from pipeline.linearizations.Linearization import LinearizationDatetimeAttr, LinearizationNumericAttr, LinearizationGeoZorder, LinearizationRandom\n",
    "\n",
    "LinearizationRandom(\"taxis\", 25).linearize()  # random shuffling\n",
    "LinearizationDatetimeAttr(\"taxis\", 25, 2).linearize()  # sort by pickup date\n",
    "LinearizationNumericAttr(\"taxis\", 25, 5).linearize()  # sort by trip distance\n",
    "LinearizationGeoZorder(\"taxis\", 25, 17, 18).linearize()  # sort by pickup location\n",
    "\n",
    "\"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot distribution of pickup location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rides dataset in hexbinned histogram\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "header = [\"tripID\", \"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"RatecodeID\", \"PULocationID\", \"DOLocationID\", \"payment_type\", \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\", \"PURepresentativeX\", \"PURepresentativeY\", \"DORepresentativeX\", \"DORepresentativeY\", \"normalized_value\", \"normalized_spatial_lag\", \"value_is_H\", \"spatial_lag_is_H\"]\n",
    "\n",
    "df = pd.read_csv(\"./taxisData.csv\", delimiter=\";\", names=header)\n",
    "\n",
    "image = plt.hexbin(\n",
    "  x=df[\"PURepresentativeX\"], \n",
    "  y=df[\"PURepresentativeY\"],\n",
    "  bins=\"log\",\n",
    "  mincnt=1,\n",
    "  gridsize=100,\n",
    ")\n",
    "\n",
    "plt.grid(True, )\n",
    "# to get the computed bins, use \n",
    "# image.get_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the time distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rides dataset in hexbinned histogram\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "header = [\"tripID\", \"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"RatecodeID\", \"PULocationID\", \"DOLocationID\", \"payment_type\", \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\", \"PURepresentativeX\", \"PURepresentativeY\", \"DORepresentativeX\", \"DORepresentativeY\", \"normalized_value\", \"normalized_spatial_lag\", \"value_is_H\", \"spatial_lag_is_H\"]\n",
    "\n",
    "df = pd.read_csv(\"./taxisData.csv\", delimiter=\";\", names=header)\n",
    "\n",
    "plt.hist(\n",
    "  pd.to_datetime(df[\"tpep_pickup_datetime\"]), \n",
    "  bins=12,\n",
    "  range=('2018-01-01 00:00:00', '2018-12-31 23:59:59'),\n",
    "  edgecolor=\"black\",\n",
    "  linewidth=1\n",
    ")\n",
    "\"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the trip distance distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rides dataset in hexbinned histogram\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "header = [\"tripID\", \"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"RatecodeID\", \"PULocationID\", \"DOLocationID\", \"payment_type\", \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\", \"PURepresentativeX\", \"PURepresentativeY\", \"DORepresentativeX\", \"DORepresentativeY\", \"normalized_value\", \"normalized_spatial_lag\", \"value_is_H\", \"spatial_lag_is_H\"]\n",
    "\n",
    "df = pd.read_csv(\"./taxisData.csv\", delimiter=\";\", names=header)\n",
    "\n",
    "plt.hist(\n",
    "  df[\"trip_distance\"], \n",
    "  bins=100,\n",
    "  range=(0, 30),\n",
    "  edgecolor=\"black\",\n",
    "  linewidth=1\n",
    ")\n",
    "\"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a linearization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "header = [\"tripID\", \"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"RatecodeID\", \"PULocationID\", \"DOLocationID\", \"payment_type\", \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\", \"PURepresentativeX\", \"PURepresentativeY\", \"DORepresentativeX\", \"DORepresentativeY\", \"normalized_value\", \"normalized_spatial_lag\", \"value_is_H\", \"spatial_lag_is_H\"]\n",
    "\n",
    "df = pd.read_csv(\"../../linearization_files/taxisLinearizationZOrder.csv\", delimiter=\";\", names=header)\n",
    "sample = np.unique(np.random.randint(low=0, high=len(df) - 1, size=100000))\n",
    "sample = sample[np.argsort(sample)]\n",
    "df.iloc[sample].plot.line(x=\"PURepresentativeX\", y=\"PURepresentativeY\", figsize=[15, 15], c=\"black\", lw=0.15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1ea470226d0cff7032cd0b9e9385b52bdf95c0a60e2d883ab49f34ab0debaa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
